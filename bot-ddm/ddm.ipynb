{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Conv1D, MaxPooling1D, Dropout, Bidirectional\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# format pandas output\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "import re\n",
    "\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   id               candidate  candidate_confidence relevant_yn  \\\n0   1  No candidate mentioned                   1.0         yes   \n1   2            Scott Walker                   1.0         yes   \n2   3  No candidate mentioned                   1.0         yes   \n3   4  No candidate mentioned                   1.0         yes   \n4   5            Donald Trump                   1.0         yes   \n\n   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n0                     1.0   Neutral                0.6578  None of the above   \n1                     1.0  Positive                0.6333  None of the above   \n2                     1.0   Neutral                0.6629  None of the above   \n3                     1.0  Positive                1.0000  None of the above   \n4                     1.0  Positive                0.7045  None of the above   \n\n   subject_matter_confidence candidate_gold             name relevant_yn_gold  \\\n0                     1.0000            NaN       I_Am_Kenzi              NaN   \n1                     1.0000            NaN    PeacefulQuest              NaN   \n2                     0.6629            NaN    PussssyCroook              NaN   \n3                     0.7039            NaN  MattFromTexas31              NaN   \n4                     1.0000            NaN       sharonDay5              NaN   \n\n   retweet_count sentiment_gold subject_matter_gold  \\\n0              5            NaN                 NaN   \n1             26            NaN                 NaN   \n2             27            NaN                 NaN   \n3            138            NaN                 NaN   \n4            156            NaN                 NaN   \n\n                                                text tweet_coord  \\\n0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n\n               tweet_created            tweet_id tweet_location  \\\n0  2015-08-07 09:54:46 -0700  629697200650592256            NaN   \n1  2015-08-07 09:54:46 -0700  629697199560069120            NaN   \n2  2015-08-07 09:54:46 -0700  629697199312482304            NaN   \n3  2015-08-07 09:54:45 -0700  629697197118861312          Texas   \n4  2015-08-07 09:54:45 -0700  629697196967903232            NaN   \n\n                user_timezone  \n0                       Quito  \n1                         NaN  \n2                         NaN  \n3  Central Time (US & Canada)  \n4                     Arizona  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>candidate</th>\n      <th>candidate_confidence</th>\n      <th>relevant_yn</th>\n      <th>relevant_yn_confidence</th>\n      <th>sentiment</th>\n      <th>sentiment_confidence</th>\n      <th>subject_matter</th>\n      <th>subject_matter_confidence</th>\n      <th>candidate_gold</th>\n      <th>name</th>\n      <th>relevant_yn_gold</th>\n      <th>retweet_count</th>\n      <th>sentiment_gold</th>\n      <th>subject_matter_gold</th>\n      <th>text</th>\n      <th>tweet_coord</th>\n      <th>tweet_created</th>\n      <th>tweet_id</th>\n      <th>tweet_location</th>\n      <th>user_timezone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>No candidate mentioned</td>\n      <td>1.0</td>\n      <td>yes</td>\n      <td>1.0</td>\n      <td>Neutral</td>\n      <td>0.6578</td>\n      <td>None of the above</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>I_Am_Kenzi</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n      <td>NaN</td>\n      <td>2015-08-07 09:54:46 -0700</td>\n      <td>629697200650592256</td>\n      <td>NaN</td>\n      <td>Quito</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Scott Walker</td>\n      <td>1.0</td>\n      <td>yes</td>\n      <td>1.0</td>\n      <td>Positive</td>\n      <td>0.6333</td>\n      <td>None of the above</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>PeacefulQuest</td>\n      <td>NaN</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n      <td>NaN</td>\n      <td>2015-08-07 09:54:46 -0700</td>\n      <td>629697199560069120</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>No candidate mentioned</td>\n      <td>1.0</td>\n      <td>yes</td>\n      <td>1.0</td>\n      <td>Neutral</td>\n      <td>0.6629</td>\n      <td>None of the above</td>\n      <td>0.6629</td>\n      <td>NaN</td>\n      <td>PussssyCroook</td>\n      <td>NaN</td>\n      <td>27</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n      <td>NaN</td>\n      <td>2015-08-07 09:54:46 -0700</td>\n      <td>629697199312482304</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>No candidate mentioned</td>\n      <td>1.0</td>\n      <td>yes</td>\n      <td>1.0</td>\n      <td>Positive</td>\n      <td>1.0000</td>\n      <td>None of the above</td>\n      <td>0.7039</td>\n      <td>NaN</td>\n      <td>MattFromTexas31</td>\n      <td>NaN</td>\n      <td>138</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n      <td>NaN</td>\n      <td>2015-08-07 09:54:45 -0700</td>\n      <td>629697197118861312</td>\n      <td>Texas</td>\n      <td>Central Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Donald Trump</td>\n      <td>1.0</td>\n      <td>yes</td>\n      <td>1.0</td>\n      <td>Positive</td>\n      <td>0.7045</td>\n      <td>None of the above</td>\n      <td>1.0000</td>\n      <td>NaN</td>\n      <td>sharonDay5</td>\n      <td>NaN</td>\n      <td>156</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n      <td>NaN</td>\n      <td>2015-08-07 09:54:45 -0700</td>\n      <td>629697196967903232</td>\n      <td>NaN</td>\n      <td>Arizona</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Load data\"\"\"\n",
    "data = pd.read_csv('../input/Sentiment.csv')\n",
    "# check data\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text sentiment\n1  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n3  RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n5  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n6  RT @warriorwoman91: I liked her and was happy ...  Negative",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RT @warriorwoman91: I liked her and was happy ...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Clean data\"\"\"\n",
    "# Keeping only the necessary columns\n",
    "data = data[['text','sentiment']]\n",
    "# keeping sentiment only Positive and Negative, remove Neutral\n",
    "data = data[data.sentiment != \"Neutral\"]\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2236\n",
      "8493\n",
      "[[   0    0    0 ... 1324 1409  743]\n",
      " [   0    0    0 ...  233  724   17]\n",
      " [   0    0    0 ...  207  371  670]\n",
      " ...\n",
      " [   0    0    0 ...   72   65    3]\n",
      " [   0    0    0 ... 1022 1423   74]\n",
      " [   0    0    0 ...  197    3  723]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Natural language processing (NLP)\"\"\"\n",
    "data['text'] = data['text'].apply(lambda a: a.lower())  # Lower words\n",
    "data['text'] = data['text'].apply((lambda a: re.sub('[^a-zA-z0-9\\s]','',a)))    # Only keep words and number\n",
    "\n",
    "# Print the sum of Positive and Negative\n",
    "print(data[ data['sentiment'] == 'Positive'].shape[0])\n",
    "print(data[ data['sentiment'] == 'Negative'].shape[0])\n",
    "\n",
    "# remove 'rt'\n",
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "\n",
    "# Tokenize sentence\n",
    "max_features = 2000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "# Transfer into a 2D Numpy array\n",
    "X = pad_sequences(X)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 14:30:46.349061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 28, 128)           256000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                6304      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 517,170\n",
      "Trainable params: 517,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Build model\"\"\"\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "# Fourth Version\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, 128, input_length=X.shape[1]))\n",
    "# model.add(Bidirectional(LSTM(64)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(2, activation='sigmoid'))\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "\n",
    "# Third Version\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Second Version\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(2,activation='softmax'))\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "\n",
    "# First Version\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "# model.add(SpatialDropout1D(0.4))\n",
    "# model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(2,activation='softmax'))\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "# plot_model(model, to_file='model.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7188, 28) (7188, 2)\n",
      "(3541, 28) (3541, 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Split dataset to train and test\"\"\"\n",
    "# Convert categorical variable into dummy/indicator variables.\n",
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-30 14:30:46.667193: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 - 36s - loss: 0.4445 - accuracy: 0.8148\n",
      "Epoch 2/7\n",
      "225/225 - 29s - loss: 0.3267 - accuracy: 0.8692\n",
      "Epoch 3/7\n",
      "225/225 - 31s - loss: 0.2878 - accuracy: 0.8837\n",
      "Epoch 4/7\n",
      "225/225 - 29s - loss: 0.2492 - accuracy: 0.9018\n",
      "Epoch 5/7\n",
      "225/225 - 33s - loss: 0.2260 - accuracy: 0.9092\n",
      "Epoch 6/7\n",
      "225/225 - 34s - loss: 0.2035 - accuracy: 0.9172\n",
      "Epoch 7/7\n",
      "225/225 - 31s - loss: 0.1800 - accuracy: 0.9275\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fad1af78130>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Train model\"\"\"\n",
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs=7, batch_size=batch_size, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 - 2s - loss: 0.4878 - accuracy: 0.8319\n",
      "score: 0.49\n",
      "acc: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Cal F1 score and acc in test dataset\n",
    "validation_size = 1500\n",
    "\n",
    "# Validate dataset : last 1500\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "# Test dataset : others\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size)\n",
    "print(\"score: %.2f\" % score)\n",
    "print(\"acc: %.2f\" % acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "1/1 - 0s\n",
      "pos_acc 56.957928802588995 %\n",
      "neg_acc 90.76406381192275 %\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "\n",
    "for x in range(len(X_validate)):\n",
    "    result = model.predict(X_validate[x].reshape(1, X_test.shape[1]), batch_size=1, verbose=2)[0]\n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0  206  633    6  150    5   55 1055   55   46    6  150]]\n",
      "1/1 - 0s\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twt = ['Meetings: Because none of us is as dumb as all of us.']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt, batch_size=1, verbose = 2)[0]\n",
    "if np.argmax(sentiment) == 0:\n",
    "    print(\"negative\")\n",
    "elif np.argmax(sentiment) == 1:\n",
    "    print(\"positive\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-794b996",
   "language": "python",
   "display_name": "PyCharm (machine-learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}